{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoderkurt/web_scraper_live_demo/blob/master/web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PHL1P61-TEsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "2f3e4e1f-fa2e-49c4-bbaa-f692b7c35654"
      },
      "cell_type": "code",
      "source": [
        "!pip install stop-words"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop-words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Running setup.py bdist_wheel for stop-words ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x4Smaip-SP5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "2bc18053-643c-46eb-e805-7b5dc2413fa9"
      },
      "cell_type": "code",
      "source": [
        "#lets write a Simple script \n",
        "#to get the 20 words and their frequency percentage \n",
        "#with highest frequency in an English Wikipedia article. \n",
        "#applications are recommender systems, chatbots and NLP, sentiment analysis,\n",
        "#data visualization,\n",
        "#market research\n",
        "\n",
        "#Beautiful Soup is a Python library \n",
        "#for pulling data out of HTML and XML files.\n",
        "from bs4 import BeautifulSoup\n",
        "#Requests is one of the most downloaded \n",
        "#Python packages of all time, \n",
        "#pulling in over 7,000,000 downloads every month.\n",
        "#HTTP library for pulling pushing and authenticating\n",
        "import requests\n",
        "#lets you do Regular expression operations\n",
        "#special text string for describing a search pattern.\n",
        "#find and replace\n",
        "import re\n",
        "#The operator module exports a \n",
        "#set of efficient functions \n",
        "#corresponding to the intrinsic operators of Python.\n",
        "#comparison, addition, greater than less then\n",
        "import operator\n",
        "#parses json, formats it\n",
        "import json\n",
        "#The module provides just one function, \n",
        "#tabulate, which takes a list of lists or another \n",
        "#tabular data type as the first argument, \n",
        "#and outputs a nicely formatted plain-text table:\n",
        "from tabulate import tabulate\n",
        "#system calls, dealw with user arguments\n",
        "import sys\n",
        "#list of common stop words various languages like the\n",
        "from stop_words import get_stop_words\n",
        "\n",
        "#get the words\n",
        "def getWordList(url):\n",
        "    word_list = []\n",
        "    #raw data\n",
        "    source_code = requests.get(url)\n",
        "    #convert to text\n",
        "    plain_text = source_code.text\n",
        "    #lxml format\n",
        "    soup = BeautifulSoup(plain_text,'lxml')\n",
        "\n",
        "    #find the words in paragraph tag\n",
        "    for text in soup.findAll('p'):\n",
        "        if text.text is None:\n",
        "            continue\n",
        "        #content\n",
        "        content = text.text\n",
        "        #lowercase and split into an array\n",
        "        words = content.lower().split()\n",
        "\n",
        "        #for each word\n",
        "        for word in words:\n",
        "            #remove non-chars\n",
        "            cleaned_word = clean_word(word)\n",
        "            #if there is still something there\n",
        "            if len(cleaned_word) > 0:\n",
        "                #add it to our word list\n",
        "                word_list.append(cleaned_word)\n",
        "\n",
        "    return word_list\n",
        "\n",
        "\n",
        "#clean word with regex\n",
        "def clean_word(word):\n",
        "    cleaned_word = re.sub('[^A-Za-z]+', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "\n",
        "def createFrquencyTable(word_list):\n",
        "    #word count\n",
        "    word_count = {}\n",
        "    for word in word_list:\n",
        "        #index is the word\n",
        "        if word in word_count:\n",
        "            word_count[word] += 1\n",
        "        else:\n",
        "            word_count[word] = 1\n",
        "\n",
        "    return word_count\n",
        "\n",
        "#remove stop words\n",
        "def remove_stop_words(frequency_list):\n",
        "    stop_words = get_stop_words('en')\n",
        "\n",
        "    temp_list = []\n",
        "    for key,value in frequency_list:\n",
        "        if key not in stop_words:\n",
        "            temp_list.append([key, value])\n",
        "\n",
        "    return temp_list\n",
        "\n",
        "#access wiki API. json format. query it for data. search tyep. shows list of possibilities\n",
        "wikipedia_api_link = \"https://en.wikipedia.org/w/api.php?format=json&action=query&list=search&srsearch=\"\n",
        "wikipedia_link = \"https://en.wikipedia.org/wiki/\"\n",
        "\n",
        "#if the search word is too small, throw error\n",
        "if(len(sys.argv) < 2):\n",
        "    print(\"Enter valid string\")\n",
        "    exit()\n",
        "\n",
        "#get the search word\n",
        "string_query = sys.argv[1]\n",
        "\n",
        "#to remove stop words or not\n",
        "if(len(sys.argv) > 2):\n",
        "    search_mode = True\n",
        "else:\n",
        "    search_mode = False\n",
        "\n",
        "#create our URL\n",
        "url = wikipedia_api_link + string_query\n",
        "\n",
        "#try-except block. simple way to deal with exceptions \n",
        "#great for HTTP requests\n",
        "try:\n",
        "    #use requests to retrieve raw data from wiki API URL we\n",
        "    #just constructed\n",
        "    response = requests.get(url)\n",
        "\n",
        "    #format that data as a JSON dictionary\n",
        "    data = json.loads(response.content.decode(\"utf-8\"))\n",
        "\n",
        "    #page title, first option\n",
        "    #show this in web browser\n",
        "    wikipedia_page_tag = data['query']['search'][0]['title']\n",
        "\n",
        "    #get actual wiki page based on retrieved title\n",
        "    url = wikipedia_link + wikipedia_page_tag\n",
        "    #get list of words from that page\n",
        "    page_word_list = getWordList(url)\n",
        "    #create table of word counts, dictionary\n",
        "    page_word_count = createFrquencyTable(page_word_list)\n",
        "    #sort the table by the frequency count\n",
        "    sorted_word_frequency_list = sorted(page_word_count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    #remove stop words if the user specified\n",
        "    if(search_mode):\n",
        "        sorted_word_frequency_list = remove_stop_words(sorted_word_frequency_list)\n",
        "\n",
        "    #sum the total words to calculate frequencies   \n",
        "    total_words_sum = 0\n",
        "    for key,value in sorted_word_frequency_list:\n",
        "        total_words_sum = total_words_sum + value\n",
        "\n",
        "    #just get the top 20 words\n",
        "    if len(sorted_word_frequency_list) > 20:\n",
        "        sorted_word_frequency_list = sorted_word_frequency_list[:20]\n",
        "\n",
        "    #create our final list which contains words, frequency (word count), percentage\n",
        "    final_list = []\n",
        "    for key,value in sorted_word_frequency_list:\n",
        "        percentage_value = float(value * 100) / total_words_sum\n",
        "        final_list.append([key, value, round(percentage_value, 4)])\n",
        "\n",
        "    #headers before the table\n",
        "    print_headers = ['Word', 'Frequency', 'Frequency Percentage']\n",
        "\n",
        "    #print the table with tabulate\n",
        "    print(tabulate(final_list, headers=print_headers, tablefmt='orgtbl'))\n",
        "\n",
        "#throw an exception in case it breaks\n",
        "except requests.exceptions.Timeout:\n",
        "    print(\"The server didn't respond. Please, try again later.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Word       |   Frequency |   Frequency Percentage |\n",
            "|------------+-------------+------------------------|\n",
            "| playmate   |          23 |                 4.8218 |\n",
            "| pmoy       |          15 |                 3.1447 |\n",
            "| playboy    |          11 |                 2.3061 |\n",
            "| year       |          11 |                 2.3061 |\n",
            "| playmates  |           9 |                 1.8868 |\n",
            "| first      |           7 |                 1.4675 |\n",
            "| model      |           6 |                 1.2579 |\n",
            "| month      |           6 |                 1.2579 |\n",
            "| appear     |           6 |                 1.2579 |\n",
            "| us         |           5 |                 1.0482 |\n",
            "| may        |           5 |                 1.0482 |\n",
            "| issue      |           5 |                 1.0482 |\n",
            "| years      |           5 |                 1.0482 |\n",
            "| december   |           5 |                 1.0482 |\n",
            "| age        |           5 |                 1.0482 |\n",
            "| featured   |           4 |                 0.8386 |\n",
            "| magazine   |           4 |                 0.8386 |\n",
            "| pictorial  |           4 |                 0.8386 |\n",
            "| women      |           4 |                 0.8386 |\n",
            "| appearance |           4 |                 0.8386 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bviJpZDISefY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}