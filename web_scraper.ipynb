{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraper.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/decoderkurt/web_scraper_live_demo/blob/master/web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PHL1P61-TEsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f96b9ad-adab-4b54-c269-f08717dcb818"
      },
      "cell_type": "code",
      "source": [
        "!pip install stop-words"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.6/dist-packages (2018.7.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Efi9JiBmUP94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets write a Simple script to get the 20 words and their frequency percentage with highest frequency in an English Wikipedia article. \n",
        "Applications are recommender systems, chatbots and NLP, sentiment analysis, data visualization, market research\n",
        "Beautiful Soup is a Python library for pulling data out of HTML and XML files.\n",
        "\n",
        "Requests is one of the most downloaded Python packages of all time, pulling in over 7,000,000 downloads every month. HTTP library for pulling pushing and authenticating\n",
        "\n",
        "lets you do Regular expression operations\n",
        "special text string for describing a search pattern.\n",
        "find and replace\n",
        "\n",
        "The operator module exports a \n",
        "set of efficient functions \n",
        "corresponding to the intrinsic operators of Python.\n",
        "comparison, addition, greater than less then\n",
        "\n",
        "parses json, formats it\n",
        "The module provides just one function, \n",
        "tabulate, which takes a list of lists or another \n",
        "tabular data type as the first argument, \n",
        "and outputs a nicely formatted plain-text table:\n",
        "system calls, dealw with user arguments\n",
        "list of common stop words various languages like the\n"
      ]
    },
    {
      "metadata": {
        "id": "x4Smaip-SP5o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import operator\n",
        "import json\n",
        "from tabulate import tabulate\n",
        "import sys\n",
        "from stop_words import get_stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AIrqv2tbVD5k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get the words\n",
        "def getWordList(url):\n",
        "    word_list = []\n",
        "    #raw data\n",
        "    source_code = requests.get(url)\n",
        "    #convert to text\n",
        "    plain_text = source_code.text\n",
        "    #lxml format\n",
        "    soup = BeautifulSoup(plain_text,'lxml')\n",
        "\n",
        "    #find the words in paragraph tag\n",
        "    for text in soup.findAll('p'):\n",
        "        if text.text is None:\n",
        "            continue\n",
        "        #content\n",
        "        content = text.text\n",
        "        #lowercase and split into an array\n",
        "        words = content.lower().split()\n",
        "\n",
        "        #for each word\n",
        "        for word in words:\n",
        "            #remove non-chars\n",
        "            cleaned_word = clean_word(word)\n",
        "            #if there is still something there\n",
        "            if len(cleaned_word) > 0:\n",
        "                #add it to our word list\n",
        "                word_list.append(cleaned_word)\n",
        "\n",
        "    return word_list\n",
        "\n",
        "def createFrquencyTable(word_list):\n",
        "    #word count\n",
        "    word_count = {}\n",
        "    for word in word_list:\n",
        "        #index is the word\n",
        "        if word in word_count:\n",
        "            word_count[word] += 1\n",
        "        else:\n",
        "            word_count[word] = 1\n",
        "\n",
        "    return word_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdclAE-7VXok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#clean word with regex\n",
        "def clean_word(word):\n",
        "    cleaned_word = re.sub('[^A-Za-z]+', '', word)\n",
        "    return cleaned_word\n",
        "\n",
        "#remove stop words\n",
        "def remove_stop_words(frequency_list):\n",
        "    stop_words = get_stop_words('en')\n",
        "\n",
        "    temp_list = []\n",
        "    for key,value in frequency_list:\n",
        "        if key not in stop_words:\n",
        "            temp_list.append([key, value])\n",
        "\n",
        "    return temp_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bviJpZDISefY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "35162f0e-0867-4880-ae48-f6494a5fbb80"
      },
      "cell_type": "code",
      "source": [
        "#access wiki API. json format. query it for data. search tyep. shows list of possibilities\n",
        "wikipedia_api_link = \"https://en.wikipedia.org/w/api.php?format=json&action=query&list=search&srsearch=\"\n",
        "wikipedia_link = \"https://en.wikipedia.org/wiki/\"\n",
        "print(len(sys.argv))\n",
        "#if the search word is too small, throw error\n",
        "if(len(sys.argv) < 2):\n",
        "    print(\"Enter valid string\")\n",
        "    exit()\n",
        "\n",
        "#get the search word\n",
        "string_query = sys.argv[1]\n",
        "\n",
        "#to remove stop words or not\n",
        "if(len(sys.argv) > 2):\n",
        "    search_mode = True\n",
        "else:\n",
        "    search_mode = False\n",
        "\n",
        "#create our URL\n",
        "url = wikipedia_api_link + string_query"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Enter valid string\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "18EPKNMtVp6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "18b6bc8a-bc70-46d5-a4b3-091642736bd7"
      },
      "cell_type": "code",
      "source": [
        "#try-except block. simple way to deal with exceptions \n",
        "#great for HTTP requests\n",
        "try:\n",
        "    #use requests to retrieve raw data from wiki API URL we\n",
        "    #just constructed\n",
        "    response = requests.get(url)\n",
        "\n",
        "    #format that data as a JSON dictionary\n",
        "    data = json.loads(response.content.decode(\"utf-8\"))\n",
        "\n",
        "    #page title, first option\n",
        "    #show this in web browser\n",
        "    wikipedia_page_tag = data['query']['search'][0]['title']\n",
        "\n",
        "    #get actual wiki page based on retrieved title\n",
        "    url = wikipedia_link + wikipedia_page_tag\n",
        "    #get list of words from that page\n",
        "    page_word_list = getWordList(url)\n",
        "    #create table of word counts, dictionary\n",
        "    page_word_count = createFrquencyTable(page_word_list)\n",
        "    #sort the table by the frequency count\n",
        "    sorted_word_frequency_list = sorted(page_word_count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    #remove stop words if the user specified\n",
        "    if(search_mode):\n",
        "        sorted_word_frequency_list = remove_stop_words(sorted_word_frequency_list)\n",
        "\n",
        "    #sum the total words to calculate frequencies   \n",
        "    total_words_sum = 0\n",
        "    for key,value in sorted_word_frequency_list:\n",
        "        total_words_sum = total_words_sum + value\n",
        "\n",
        "    #just get the top 20 words\n",
        "    if len(sorted_word_frequency_list) > 20:\n",
        "        sorted_word_frequency_list = sorted_word_frequency_list[:20]\n",
        "\n",
        "    #create our final list which contains words, frequency (word count), percentage\n",
        "    final_list = []\n",
        "    for key,value in sorted_word_frequency_list:\n",
        "        percentage_value = float(value * 100) / total_words_sum\n",
        "        final_list.append([key, value, round(percentage_value, 4)])\n",
        "\n",
        "    #headers before the table\n",
        "    print_headers = ['Word', 'Frequency', 'Frequency Percentage']\n",
        "\n",
        "    #print the table with tabulate\n",
        "    print(tabulate(final_list, headers=print_headers, tablefmt='orgtbl'))\n",
        "\n",
        "#throw an exception in case it breaks\n",
        "except requests.exceptions.Timeout:\n",
        "    print(\"The server didn't respond. Please, try again later.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Word           |   Frequency |   Frequency Percentage |\n",
            "|----------------+-------------+------------------------|\n",
            "| unincorporated |          62 |                 4.0763 |\n",
            "| areas          |          51 |                 3.3531 |\n",
            "| area           |          25 |                 1.6437 |\n",
            "| states         |          22 |                 1.4464 |\n",
            "| county         |          15 |                 0.9862 |\n",
            "| may            |          15 |                 0.9862 |\n",
            "| government     |          15 |                 0.9862 |\n",
            "| place          |          15 |                 0.9862 |\n",
            "| new            |          14 |                 0.9204 |\n",
            "| incorporated   |          14 |                 0.9204 |\n",
            "| local          |          12 |                 0.789  |\n",
            "| municipal      |          12 |                 0.789  |\n",
            "| land           |          11 |                 0.7232 |\n",
            "| municipalities |          11 |                 0.7232 |\n",
            "| city           |          10 |                 0.6575 |\n",
            "| state          |          10 |                 0.6575 |\n",
            "| communities    |          10 |                 0.6575 |\n",
            "| united         |          10 |                 0.6575 |\n",
            "| name           |          10 |                 0.6575 |\n",
            "| populated      |           9 |                 0.5917 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UzVA0sG2WNGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}